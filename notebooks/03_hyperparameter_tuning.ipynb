{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5e6faa",
   "metadata": {},
   "source": [
    "# 03 â€“ Hyperparameter Tuning with Bayesian Optimization\n",
    "Use bayesian-optimization to tune a RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_esti... | max_depth | max_fe... | min_sa... | min_sa... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.9737882\u001b[39m | \u001b[35m177.99726\u001b[39m | \u001b[35m4.9293377\u001b[39m | \u001b[35m0.8929409\u001b[39m | \u001b[35m12.820070\u001b[39m | \u001b[35m7.3726532\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.9609985\u001b[39m | \u001b[39m110.29224\u001b[39m | \u001b[39m19.518557\u001b[39m | \u001b[39m0.8659541\u001b[39m | \u001b[39m5.8221039\u001b[39m | \u001b[39m2.6364247\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.9750126\u001b[39m | \u001b[35m191.70225\u001b[39m | \u001b[35m8.8678758\u001b[39m | \u001b[35m0.6198051\u001b[39m | \u001b[35m9.7750103\u001b[39m | \u001b[35m3.6210622\u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.9788734\u001b[39m | \u001b[35m405.92644\u001b[39m | \u001b[35m6.2319017\u001b[39m | \u001b[35m0.4337157\u001b[39m | \u001b[35m8.5945131\u001b[39m | \u001b[35m5.1046298\u001b[39m |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "df = pd.read_csv(Path('../data/raw/creditcard.csv'))\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "cols_to_scale = ['Amount'] + (['Time'] if 'Time' in X.columns else [])\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_valid[cols_to_scale] = scaler.transform(X_valid[cols_to_scale])\n",
    "\n",
    "def cv_auc(n_estimators, max_depth, max_features, min_samples_split, min_samples_leaf):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    min_samples_leaf = int(min_samples_leaf)\n",
    "    max_features = max(min(max_features, 1.0), 0.1)\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth if max_depth>0 else None,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    proba = clf.predict_proba(X_valid)[:,1]\n",
    "    return roc_auc_score(y_valid, proba)\n",
    "\n",
    "pbounds = {\n",
    "    'n_estimators': (100, 600),\n",
    "    'max_depth': (4, 20),\n",
    "    'max_features': (0.2, 1.0),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 10),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=cv_auc,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=8, n_iter=20)\n",
    "print('Best params:', optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603ade1-5f12-4ec6-8e6d-d1927beebd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the single best result (score + params)\n",
    "print(\"Best result:\", optimizer.max)\n",
    "\n",
    "# Extract only the best params\n",
    "best_params = optimizer.max[\"params\"]\n",
    "\n",
    "# Cast to the correct types for sklearn\n",
    "best_params = {\n",
    "    \"n_estimators\": int(best_params[\"n_estimators\"]),\n",
    "    \"max_depth\": int(best_params[\"max_depth\"]) if int(best_params[\"max_depth\"]) > 0 else None,\n",
    "    \"max_features\": float(best_params[\"max_features\"]),     # stays float in (0,1]\n",
    "    \"min_samples_split\": int(best_params[\"min_samples_split\"]),\n",
    "    \"min_samples_leaf\": int(best_params[\"min_samples_leaf\"]),\n",
    "}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3850718-d4da-472e-b82b-f009c7d15207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
